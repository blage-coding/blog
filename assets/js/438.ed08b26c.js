(window.webpackJsonp=window.webpackJsonp||[]).push([[438],{757:function(_,v,l){"use strict";l.r(v);var i=l(4),t=Object(i.a)({},(function(){var _=this,v=_._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("h1",{attrs:{id:"llm入门"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#llm入门"}},[_._v("#")]),_._v(" LLM入门")]),_._v(" "),v("h2",{attrs:{id:"提示工程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#提示工程"}},[_._v("#")]),_._v(" 提示工程")]),_._v(" "),v("ul",[v("li",[_._v("清晰、具体的指令提示\n"),v("ul",[v("li",[_._v("区分指令和文本内容：使用特殊的符号区分指令、输入文本内容")]),_._v(" "),v("li",[_._v("指定输出的格式：让模型将回答转化为结构化格式输出，比如直接返回json格式")]),_._v(" "),v("li",[_._v("让模型能够针对问题自主进行校验和判断，类似于if-else执行输出不同的结果")]),_._v(" "),v("li",[_._v("few-shot少样本提示：提供几个样例，告诉模型正确的输出格式")]),_._v(" "),v("li",[_._v("拆分任务，明确步骤：指定完成任务所需要的步骤")]),_._v(" "),v("li",[_._v("引导模型自主思考，做出判断并给出思路")])])]),_._v(" "),v("li",[_._v("迭代优化\n"),v("ul",[v("li",[_._v("输出长度限制")]),_._v(" "),v("li",[_._v("指明关注内容")]),_._v(" "),v("li",[_._v("将输出内容格式化为表格和HTML格式")])])]),_._v(" "),v("li",[_._v("文本概括\n"),v("ul",[v("li",[_._v("长度限制：“生成某个评论的简短摘要，最多不超过30词”")]),_._v(" "),v("li",[_._v("输出侧重的角度不同：让模型输出的内容可以侧重关注某个方面")]),_._v(" "),v("li",[_._v("命令模型只提取输出某个关键信息")]),_._v(" "),v("li",[_._v("多段长文本叙述：for循环依次概括每一段文本，拼接最终结果")])])]),_._v(" "),v("li",[_._v("情感推断&主题判断\n"),v("ul",[v("li",[v("strong",[_._v("模型识别分类，并指定类别名称进行输出，方便后续的处理")])]),_._v(" "),v("li",[_._v("指定json格式、类别名称")])])]),_._v(" "),v("li",[_._v("文本转换\n"),v("ul",[v("li",[_._v("需要在高质量平行语料上Fine-Tune")]),_._v(" "),v("li",[_._v("格式转换：HTML转换JSON")]),_._v(" "),v("li",[_._v("语法错误、格式纠错")])])]),_._v(" "),v("li",[_._v("文本扩展\n"),v("ul",[v("li",[_._v("根据输入的短文本，生成更加丰富的长文本")]),_._v(" "),v("li",[_._v("通过设置temperature来控制生成质量，值越小则输出概率最高的内容，每轮输出的内容越稳定；值越大则输出更多样化，输出的内容不稳定")]),_._v(" "),v("li",[v("strong",[_._v("多次利用大模型，输出得到更多原始文本相关的信息，比如情感、主题，最后和原始文本一并输入模型进行提问")])])])]),_._v(" "),v("li",[_._v("不同角色——聊天问答系统\n"),v("ul",[v("li",[_._v("role——system："),v("strong",[_._v("设置assistant的行为、角色扮演、整个问答期望的输入和输出内容和格式")]),_._v("。指定整个完整的对话流程，包括接收到用户的消息之后，输出什么内容进行回答")]),_._v(" "),v("li",[_._v("role——assistant和user来进行交互和对话")])])])]),_._v(" "),v("h2",{attrs:{id:"基于chatgpt的问答系统"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基于chatgpt的问答系统"}},[_._v("#")]),_._v(" 基于ChatGPT的问答系统")]),_._v(" "),v("ul",[v("li",[_._v("输入内容校验，防止prompt注入\n"),v("ul",[v("li",[_._v("使用分隔符、换行符、用户输入拼接上校验信息作为user_message")]),_._v(" "),v("li",[_._v("system当中定义校验的非法类型，通过判断用户输入来判断是否属于非法类型，并进行处理和返回")])])]),_._v(" "),v("li",[_._v("思维链\n"),v("ul",[v("li",[_._v("system声明每个步骤进行怎样的推理，并可以让模型输出每个步骤的推理")]),_._v(" "),v("li",[_._v("隐藏中间推理过程，只返回用户关心的输出内容")]),_._v(" "),v("li",[_._v("step by step提示链：拆分成子任务多轮交互，成功率更高。其中每个拆分成的子任务执行方式可以有多种：\n"),v("ol",[v("li",[_._v("LLM交互")]),_._v(" "),v("li",[_._v("数据库")]),_._v(" "),v("li",[_._v("程序API控制")])])]),_._v(" "),v("li",[_._v("知识检索："),v("strong",[_._v("没有必要将所有信息库内容都加入system当中，可以按需动态加载与用户问题相关的知识")]),_._v(" "),v("ul",[v("li",[_._v("将所有知识内容存入json文件当中，然后根据问题按需读取")]),_._v(" "),v("li",[_._v("文本嵌入embedding，高效知识检索，实现"),v("strong",[_._v("模糊或语义搜索")])])])])])]),_._v(" "),v("li",[_._v("输出评估\n"),v("ul",[v("li",[_._v("使用API输出敏感类型的得分，并根据是否有害输出新的响应或是替代答案(没必要)")]),_._v(" "),v("li",[v("strong",[_._v("启动另一个system角色，和模型交互来判断前一个回答是否符合要求")])])])]),_._v(" "),v("li",[_._v("端到端问答系统\n"),v("ol",[v("li",[_._v("输入信息进行校验")]),_._v(" "),v("li",[_._v("相关知识检索：根据输入判断属于哪个类别、主题、方向(模型交互、正则表达式)，然后根据这个方向进行详细的知识检索")]),_._v(" "),v("li",[_._v("模型问答&少样本提示：user——原始问题的输入；assistant——提供辅助("),v("strong",[_._v("详细知识")]),_._v(")")]),_._v(" "),v("li",[_._v("输出质量校验和反馈")])])]),_._v(" "),v("li",[_._v("prompt效果评估\n"),v("ul",[v("li",[_._v("指定输出格式、少样本提示few_shot")]),_._v(" "),v("li",[_._v("回归测试：确保改进后的prompt engineer不会对先前的样例造成影响")]),_._v(" "),v("li",[_._v("效果评估\n"),v("ul",[v("li",[_._v("对于有准确答案的问题，计算每次回答的准确率")]),_._v(" "),v("li",[v("strong",[_._v("对于答案比较模糊的问题，交给LLM进行评估")]),_._v("：\n"),v("ul",[v("li",[_._v("提供一个专家理想的答案")]),_._v(" "),v("li",[_._v("交给LLM评估代理回答和专家回答之间的相似性，关注在内容上，忽略样式、语法、细微差异")])])])])])])])]),_._v(" "),v("h2",{attrs:{id:"langchain程序开发"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#langchain程序开发"}},[_._v("#")]),_._v(" LangChain程序开发")]),_._v(" "),v("ul",[v("li",[_._v("提示模板\n"),v("ul",[v("li",[_._v("from_template：构造提示模板")]),_._v(" "),v("li",[_._v("format_messages：将变量插入提示模板字符串")]),_._v(" "),v("li",[_._v("调用chat方法进行模型交互")]),_._v(" "),v("li",[_._v("设置输出解释器format_instructions，将返回的str类型输出通过解析器格式化为JSON")])])]),_._v(" "),v("li",[_._v("储存memory：保存整个对话的上下文对话历史\n"),v("ul",[v("li",[_._v("外部存储上下文信息ConversationBufferMemory")]),_._v(" "),v("li",[_._v("对话缓存窗口存储ConversationBufferWindowMemory：只保存上一轮的对话记录")]),_._v(" "),v("li",[_._v("对话字符缓存储存ConversationTokenBufferMemory：内存限制保存的tokne数，超出则删除最早对话的token")]),_._v(" "),v("li",[_._v("对话摘要缓存存储ConversationSummaryBufferMemory")])])]),_._v(" "),v("li",[_._v("LLM链：将模型和prompt结合构成LLMChain对象\n"),v("ul",[v("li",[_._v("简单顺序链：多个LLM链拼接在一起，并顺序执行。每个链模板输入和输出只有一个，"),v("strong",[_._v("前一个链的输出作为下一个链条模板的输入")]),_._v("。")]),_._v(" "),v("li",[_._v("顺序链：通过指定输出结果的模板key名称，实现多输入和多输出的效果，任意"),v("strong",[_._v("组合排列")]),_._v("不同模型链的结果。")]),_._v(" "),v("li",[_._v("路由链：根据当前链的输出结果，选择下一个要调用哪一个链，\n"),v("ul",[v("li",[_._v("定义多个目标链+默认链(不能明确该路由哪个目标链时，则调用默认链)")]),_._v(" "),v("li",[v("strong",[_._v("定义一个路由链，并和多提示的模板进行绑定")]),_._v("。"),v("font",{attrs:{color:"red"}},[v("strong",[_._v("本质上也是将输入内容通过LLM进行交互，判断出和哪个目标链相似")])]),_._v("(属于哪个目标链的类别)")],1),_._v(" "),v("li",[_._v("路由输出解析对象RouterOutputParser")])])])])]),_._v(" "),v("li",[_._v("基于文档问答\n"),v("ul",[v("li",[_._v("直接使用向量数据库进行查询")]),_._v(" "),v("li",[_._v("Embeddings+向量存储索引：指定向量表征模型OpenAIEmbeddings+文档列表构建向量数据库。并调用similarity_search进行相似搜索")]),_._v(" "),v("li",[_._v("检索问答链：\n"),v("ul",[v("li",[_._v("指定LLM负责文本生成")]),_._v(" "),v("li",[_._v("指定传入链类型(根据什么方式使用文档中的相关块信息进行问答)：\n"),v("ul",[v("li",[_._v("stuff：查询得到的文档组合成一个文档传入下一步")]),_._v(" "),v("li",[_._v("map_reduce：对于文档每个块的知识信息，都调用LLM交互询问（并行）。最后再使用LLM将所有回答总结成答案")]),_._v(" "),v("li",[_._v("Refine：循坏提问的方式，前n个块的回答结果会和第n+1个块，一并输入到LLM当中进行问答")]),_._v(" "),v("li",[_._v("Map_rerank：每个块调用LLM进行询问，并要求模型输出结果包含一个可信度分数，最终选择分数最高的回答作为结果。")])])])])]),_._v(" "),v("li",[v("strong",[_._v("自动化评估")]),_._v("：基于QAGenerateChain自动化生成样本的测试集。本质上还是根据输入的向量知识块**，利用定制化prompt基于LLM生成问答测试集**，其中提示词当中会有<基于给出的文本知识，生成问答对>相关的字词。")])])]),_._v(" "),v("li",[_._v("Agent代理\n"),v("ul",[v("li",[_._v("创建LLM、Tool(包括计算器工具、维基百科，PythonREPLTool，自定义的工具函数——需要注释)、Agent")]),_._v(" "),v("li",[v("strong",[_._v("本质上也是通过多轮LLM，输出判断使用哪个工具？然后Agent会调用对应的Tool函数，再将结果输入模型询问")]),_._v("。从而利用外部工具获取更加有价值的知识，与模型进行交互")])])])]),_._v(" "),v("h2",{attrs:{id:"langchain访问个人数据"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#langchain访问个人数据"}},[_._v("#")]),_._v(" LangChain访问个人数据")]),_._v(" "),v("ul",[v("li",[_._v("文档加载：PDF、音频、markdown等等文档")]),_._v(" "),v("li",[_._v("文档分割：按照长度分割、按照某个字符进行分割、递归字符分割(对每段文本依次使用每个分割符进行分割)、Token（不支持中文）、Markdown——根据标题分割")]),_._v(" "),v("li",[_._v("向量数据库+词向量\n"),v("ul",[v("li",[_._v("获取每个chunk进行Embeddings，相近内容的向量在嵌入空间比较接近。")]),_._v(" "),v("li",[_._v("持久化")])])]),_._v(" "),v("li",[_._v("retrieval检索\n"),v("ul",[v("li",[_._v("similarity_search相似性搜索")]),_._v(" "),v("li",[_._v("MMR最大边际相关性：去除冗余的信息、提供多样性数据(相关度，相似度——"),v("strong",[_._v("适合多样性需求文本")]),_._v(")")]),_._v(" "),v("li",[_._v("元数据filter：过滤掉无用的文本。但是需要手动设置。另一种方法是"),v("strong",[_._v("通过LLM交互")]),_._v("，通过LLM提取对应的敏感过滤信息")]),_._v(" "),v("li",[_._v("压缩：通过LLM获取得到压缩后的chunk，压缩得到的知识只和问题相关")])])]),_._v(" "),v("li",[_._v("上下文问题\n"),v("ul",[v("li",[_._v("讲历史对话信息和当前查询合并，再将整个内容从向量数据库进行检索")])])])])])}),[],!1,null,null,null);v.default=t.exports}}]);